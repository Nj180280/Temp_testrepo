# -*- coding: utf-8 -*-
"""linear_regression_models.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UXWgpRxQiB-y5xgxbWL7tsgkxuZztqUt

- [Load and Check Data](#-1)
- [Data Preparation](#0)
- [Simple Linear Regression](#1)
- [Ridge Regression](#4)
- [Lasso Regression](#5)
- [ElasticNet Regression](#6)
- [Random Forest Regression](#7)
- [Desision Tree Regression](#8)
- [Gradient Bossting Regressor](#9)
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
plt.style.use("seaborn-whitegrid")
import warnings
warnings.filterwarnings("ignore")

"""# Load and Check Data <a id="-1"></a>"""

y_2018 = pd.read_csv("/content/2018.csv");
y_2019 = pd.read_csv("/content/2019.csv");

data = pd.concat([y_2018,y_2019],sort=False)
data

"""# Veriable Description

1. Overall rank: Ranking of countries by happiness level
2. Country or region: Country or region names
3. Score: Happiness scores
4. GDP per capita: Value representing the country's income and expense levels
5. Social support
6. Healthy life expectancy
7. Freedom to make life choices
8. Generosity
9. Perceptions of corruption
"""

data.describe().T

data.info()

"""Let's change the column names for convenience."""

data.rename(columns={
    "Overall rank": "rank",
    "Country or region": "country",
    "Score": "score",
    "GDP per capita": "gdp",
    "Social support": "social",
    "Healthy life expectancy": "healthy",
    "Freedom to make life choices": "freedom",
    "Generosity": "generosity",
    "Perceptions of corruption": "corruption"
},inplace=True)
del data["rank"]

"""# Missing Value"""

data.columns[data.isnull().any()]

"""There are empty elements in only one column. Let's look at how many."""

data.isnull().sum()

data[data["corruption"].isnull()]

avg_data_corruption = data[data["score"] > 6.774].mean().corruption
data.loc[data["corruption"].isnull(),["corruption"]] = avg_data_corruption
data[data["corruption"].isnull()]

"""# Data Preparation <a id="0"></a>
## Inconsistent Observation
* 95% of a machine learning model is said to be preprocessing and 5% is model selection. For this we need to teach the data to the model correctly. In order to prepare the available data for machine learning, we must apply certain pre-processing methods. One of these methods is the analysis of outliers. The outlier is any data point that is substantially different from the rest of the observations in a data set. In other words, it is the observation that goes far beyond the general trend.

![](https://miro.medium.com/max/854/1*RW-vfIbKZh-UGsLfTAWpyw.png)

Outlier values behave differently from other data models and they increase the error with overfitting, so the outlier model must be detected and some operations must be performed on it.
### 1.Using Box Graph
We can see contradictory observations with many visualization techniques. One of them is the box chart. If there is an outlier, this is drawn as the point, but the other population is grouped together and displayed in boxes.
"""

df = data.copy()
df = df.select_dtypes(include=["float64","int64"])
df.head()

column_list = ["score","gdp","social","healthy","freedom","generosity","corruption"]
for col in column_list:
    sns.boxplot(x = df[col])
    plt.xlabel(col)
    plt.show()

"""We have observed that there are outliers in the "social" and "corruption" column. This may cause us to negatively affect us while training our data set."""

# for corruption
df_table = df["corruption"]

Q1 = df_table.quantile(0.25)
Q3 = df_table.quantile(0.75)
IQR = Q3 - Q1

lower_bound = Q1 - 1.5*IQR
upper_bound = Q3 + 1.5*IQR
print("lower bound is " + str(lower_bound))
print("upper bound is " + str(upper_bound))
print("Q1: ", Q1)
print("Q3: ", Q3)

outliers_vector = (df_table < (lower_bound)) | (df_table > (upper_bound))
outliers_vector

outliers_vector = df_table[outliers_vector]
outliers_vector.index.values

"""Deleting data is not suitable for this data set. That's why we will fill out the outliers with the average."""

df_table = data.copy()
df_table["corruption"].iloc[outliers_vector.index.values] = df_table["corruption"].mean()
df_table["corruption"].iloc[outliers_vector.index.values]

data = df_table

"""# Simple Linear Regressions <a id="1"></a>
Simple linear regression is a statistical method that allows us to summarize and analyze the relationships between two continuous (quantitative) variables:

## score - gdp
Firstly let's observe the relationship between gdp and score with the help of graphics.
* independent variable : x
* dependent variable : y

### Simple Linear Regression - Model
"""

from sklearn.linear_model import LinearRegression

# Assuming X and y are defined as in your previous code snippet
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

lr_model = LinearRegression()
lr_model.fit(X_train, y_train)

# Plotting coefficients against feature indices
plt.figure(figsize=(10, 6))
plt.bar(range(len(X.columns)), lr_model.coef_)
plt.xlabel('Feature Index')
plt.ylabel('Coefficient Value')
plt.title('Feature Coefficients for Linear Regression')
plt.xticks(range(len(X.columns)), X.columns, rotation=45)
plt.show()

"""### Simple Linear Regression - Prediction"""

from sklearn.metrics import mean_squared_error
from sklearn.model_selection import cross_val_score

# Assuming X and y are defined as in your previous code snippet
lr_model = LinearRegression()
lr_model.fit(X_train, y_train)

# Training error
y_pred_train = lr_model.predict(X_train)
train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))

print("Train Predictions:", y_pred_train[0:10])
print("Actual Train Values:", y_train[0:10].values)
print("Train RMSE:", train_rmse)

# Cross-validated RMSE
cv_rmse = np.sqrt(np.mean(-cross_val_score(lr_model, X_train, y_train, cv=20, scoring="neg_mean_squared_error")))
print("Cross-Validated RMSE:", cv_rmse)

# Test error
y_pred_test = lr_model.predict(X_test)
test_rmse_lr = np.sqrt(mean_squared_error(y_test, y_pred_test))
print("Test Error:", test_rmse)

"""# Ridge Regression <a id="4"></a>
The aim is to find the coefficients that minimize the sum of error squares by applying a penalty to these coefficients.
* It is resistant to over learning.
* It is biased but its variance is low.
* It is better than OLS when there are too many parameters.
* Builds a model with all variables. It does not exclude the unrelated variables from the model, it approximates its coefficients to zero.

![](https://i.ibb.co/2SJtqyB/Ek-A-klama-2020-04-21-202339.jpg)

* The delta parameter that gives the smallest "cross validation" value is selected.
* With this delta selected, the model is fit for observations again.

## Ridge Regression - Model
"""

# Required Libraries
import numpy as np
import pandas as pd
from sklearn.linear_model import Ridge
from sklearn.metrics import mean_squared_error,r2_score
from sklearn.model_selection import train_test_split
from sklearn import model_selection
from sklearn.linear_model import RidgeCV

X = df.drop("score",axis=1)
y = df["score"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

ridge_model = Ridge(alpha=0.1).fit(X_train, y_train)
ridge_model

ridge_model.coef_

"""An alpha value will be assigned with each coefficient. Error coefficients will be examined according to these values."""

ridge_model.intercept_

lambdas = 10**np.linspace(10,-2,100)*0.5 # Creates random numbers
ridge_model =  Ridge()
coefs = []

for i in lambdas:
    ridge_model.set_params(alpha=i)
    ridge_model.fit(X_train,y_train)
    coefs.append(ridge_model.coef_)

ax = plt.gca()
ax.plot(lambdas, coefs)
ax.set_xscale("log")

"""In contrast to the different beta values, the changes in the coefficients of the variables in our data set appear in the graph above. As can be seen, as the coefficients increase, it approaches zero.

## Ridge Regression - Prediction
"""

ridge_model = Ridge().fit(X_train,y_train)

y_pred = ridge_model.predict(X_train)

print("predict: ", y_pred[0:10])
print("real: ", y_train[0:10].values)

RMSE = np.mean(mean_squared_error(y_train,y_pred)) # rmse = square root of the mean of error squares
print("train error: ", RMSE)

Verified_RMSE = np.sqrt(np.mean(-cross_val_score(ridge_model, X_train, y_train, cv=20, scoring="neg_mean_squared_error")))
print("Verified_RMSE: ", Verified_RMSE)

"""There are two values ​​above. One of them is unverified, the other is the values ​​that represent the square root of the sum of the verified error squares. As you can see, the unverified value is almost half of the verified value. This result shows us that it is more correct to use the second method, not the first method, while taking the square root of the mean of the error squares.

## Ridge Model - Model Tuning
"""

ridge_model = Ridge(10).fit(X_train,y_train)
y_pred = ridge_model.predict(X_test)
np.sqrt(mean_squared_error(y_test,y_pred))

ridge_model = Ridge(30).fit(X_train,y_train)
y_pred = ridge_model.predict(X_test)
np.sqrt(mean_squared_error(y_test,y_pred))

ridge_model = Ridge(90).fit(X_train,y_train)
y_pred = ridge_model.predict(X_test)
np.sqrt(mean_squared_error(y_test,y_pred))

"""We can find out which value will work better by trial and error. But with the method we will use below, we can find the most appropriate value more easily and quickly."""

lambdas1 = 10**np.linspace(10,-2,100)
lambdas2 = np.random.randint(0,1000,100)

ridgeCV = RidgeCV(alphas = lambdas1,scoring = "neg_mean_squared_error", cv=10)
ridgeCV.fit(X_train,y_train)

"""We can use alpha_ feature to attract the most appropriate value."""

ridgeCV.alpha_

# final model
ridge_tuned = Ridge(alpha = ridgeCV.alpha_).fit(X_train,y_train)
y_pred = ridge_tuned.predict(X_test)
np.sqrt(mean_squared_error(y_test,y_pred))

# for lambdas2
lambdas2 = np.random.uniform(0.001, 1000, 100)  # Generating random alpha values between 0.001 and 1000

ridgeCV = RidgeCV(alphas=lambdas2, scoring="neg_mean_squared_error", cv=10)
ridgeCV.fit(X_train, y_train)
ridge_tuned = Ridge(alpha=ridgeCV.alpha_).fit(X_train, y_train)
y_pred = ridge_tuned.predict(X_test)
np.sqrt(mean_squared_error(y_test, y_pred))

"""# Lasso Regression <a id="5"></a>
The aim is to find the coefficients that minimize the sum of error squares by applying a penalty to these coefficients.
* Lasso regression = L1
* Ridge regression = L2

* It has been proposed to eliminate the disadvantage of leaving the related-unrelated variables in the model of the Ridge regression.
* Coefficients near zero in Lasso.
* But when the L1 norm is big enough in lambda, some coefficients make it zero. Thus, it makes the selection of the variable.
* It is very important to choose Lambda correctly, CV is used here too.
* Ridge and Lasso methods are not superior to each other.

## Lasso Regression - Model
"""

# Required Libraries
import numpy as np
import pandas as pd
from sklearn.linear_model import Ridge,Lasso
from sklearn.metrics import mean_squared_error,r2_score
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn import model_selection
from sklearn.linear_model import RidgeCV, LassoCV

X = df.drop("score",axis=1)
y = df["score"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)

lasso_model = Lasso().fit(X_train,y_train)

print("intercept: ", lasso_model.intercept_)
print("coef: ", lasso_model.coef_)

# coefficients for different lambda values

alphas = np.random.randint(0,10000,10)
lasso = Lasso()
coefs = []

for a in alphas:
    lasso.set_params(alpha=a)
    lasso.fit(X_train,y_train)
    coefs.append(lasso.coef_)

ax = plt.gca()
ax.plot(alphas,coefs)
ax.set_xscale("log")

"""## Lasso Regression - Prediction"""

lasso_model

lasso_model.predict(X_train)[0:5]

lasso_model.predict(X_test)[0:5]

y_pred = lasso_model.predict(X_test)
np.sqrt(mean_squared_error(y_test,y_pred))

r2_score(y_test,y_pred)

"""## Lasso Regression - Model Tuning"""

lasso_cv_model = LassoCV(cv=10,max_iter=100000).fit(X_train,y_train)
lasso_cv_model

lasso_cv_model.alpha_

lasso_tuned = Lasso().set_params(alpha= lasso_cv_model.alpha_).fit(X_train,y_train)
y_pred = lasso_tuned.predict(X_test)
np.sqrt(mean_squared_error(y_test,y_pred))

"""# ElasticNet Regression <a id="6"></a>
* The aim is to find the coefficients that minimize the sum of error squares by applying a penalty.
* ElasticNet combines L1 and L2 approaches.The aim is to find the coefficients that minimize the sum of error squares by applying a penalty.

## ElasticNet Regression - Model & Prediction
"""

# Required Libraries
import numpy as np
import pandas as pd
from sklearn.linear_model import Ridge,Lasso,ElasticNet
from sklearn.metrics import mean_squared_error,r2_score
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn import model_selection
from sklearn.linear_model import RidgeCV, LassoCV, ElasticNetCV

X = df.drop("score",axis=1)
y = df["score"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)

enet_model = ElasticNet().fit(X_train,y_train)

enet_model.coef_

enet_model.intercept_

# prediction
enet_model.predict(X_train)[0:10]

enet_model.predict(X_test)[0:10]

y_pred = enet_model.predict(X_test)
np.sqrt(mean_squared_error(y_test,y_pred))

"""### ElasticNet Regression - Fine Tuning"""

from sklearn.linear_model import ElasticNet

# Hyperparameters to tune
param_grid_enet = {
    'alpha': [0.001, 0.01, 0.1, 1, 10],
    'l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9]
}

# Initialize Elastic Net Regressor
enet_model = ElasticNet(random_state=42)
# Perform Randomized Search Cross Validation
from sklearn.model_selection import RandomizedSearchCV
enet_cv = RandomizedSearchCV(estimator=enet_model, param_distributions=param_grid_enet,
                             scoring='neg_mean_squared_error', cv=10, n_iter=10, random_state=42)
enet_cv.fit(X_train, y_train)

# Get the best hyperparameters
best_params_enet = enet_cv.best_params_
print("Best Hyperparameters:", best_params_enet)
# Train a final model using the best hyperparameters
best_enet_model = ElasticNet(**best_params_enet, random_state=42)
best_enet_model.fit(X_train, y_train)

# Predict using the tuned model
y_pred_enet = best_enet_model.predict(X_test)
test_rmse_enet = np.sqrt(mean_squared_error(y_test, y_pred_enet))
print("Test RMSE with Tuned Elastic Net Model:", test_rmse_enet)

"""# Random Forest Regression <a id="6"></a>
* Random Forest Regression aims to minimize prediction errors by constructing an ensemble of decision trees. Instead of using a single tree, it aggregates multiple trees to make predictions.

* In essence, the Random Forest Regression minimizes prediction errors by aggregating the predictions from numerous trees. Each tree is trained on a random subset of the data and a random subset of features, reducing the risk of overfitting and increasing model robustness.

* While Random Forest doesn't involve coefficients like linear regression, it employs strategies like feature randomness and tree ensembling to mitigate overfitting and improve prediction accuracy. The model is geared towards reducing the variance without necessarily imposing explicit penalties as in L1 or L2 regularization

## Random Forest Regression - Model
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split

# Assuming X and y are defined as in your previous code snippet
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

rf_model = RandomForestRegressor(random_state=42)
rf_model.fit(X_train, y_train)

# Visualizing feature importances for different tree depths
max_depths = [2, 5, 10, 20, 50]  # Example list of tree depths to explore
feature_importances = []

for depth in max_depths:
    rf_model.set_params(max_depth=depth)
    rf_model.fit(X_train, y_train)
    feature_importances.append(rf_model.feature_importances_)

# Plotting feature importances against tree depths
plt.figure(figsize=(10, 6))
for i in range(len(X.columns)):
    plt.plot(max_depths, [importance[i] for importance in feature_importances], label=X.columns[i])

plt.xlabel('Max Depth of Trees')
plt.ylabel('Feature Importance')
plt.title('Feature Importances for Random Forest Regressor')
plt.legend()
plt.show()

"""### Random Forest Regression - Prediction"""

# Assuming X and y are defined as in your previous code snippet
rf_model = RandomForestRegressor(random_state=42)
rf_model.fit(X_train, y_train)

# Training error
y_pred_train = rf_model.predict(X_train)
train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))

print("Train Predictions:", y_pred_train[0:10])
print("Actual Train Values:", y_train[0:10].values)

print("Train RMSE:", train_rmse)

# Cross-validated RMSE
cv_rmse = np.sqrt(np.mean(-cross_val_score(rf_model, X_train, y_train, cv=20, scoring="neg_mean_squared_error")))
print("Cross-Validated RMSE:", cv_rmse)

# Test error
y_pred_test = rf_model.predict(X_test)
test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))
print("Test Error:", test_rmse)

"""### Random Forest Regresssion - Model Tuning"""

# Hyperparameters to tune
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

# Initialize Random Forest Regressor
rf_model = RandomForestRegressor(random_state=42)

# Perform Randomized Search Cross Validation
from sklearn.model_selection import RandomizedSearchCV
rf_cv = RandomizedSearchCV(estimator=rf_model, param_distributions=param_grid,
                           scoring='neg_mean_squared_error', cv=10, n_iter=10, random_state=42)
rf_cv.fit(X_train, y_train)

# Get the best hyperparameters
best_params = rf_cv.best_params_
print("Best Hyperparameters:", best_params)

# Train a final model using the best hyperparameters
best_rf_model = RandomForestRegressor(**best_params, random_state=42)
best_rf_model.fit(X_train, y_train)

# Predict using the tuned model
y_pred = best_rf_model.predict(X_test)
test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))
print("Test RMSE with Tuned Model:", test_rmse)

"""### Decision Tree Regression
* Decision Tree Regression predicts outcomes by structuring data into a tree-like flowchart, minimizing errors by segmenting data based on features.
* It forms decision rules at each node, recursively splitting data, capturing complex relationships, and offering interpretability without relying on coefficients.
* While powerful in learning intricate patterns, it's prone to overfitting, mitigated through techniques like limiting tree depth without explicit regularization penalties.

### Decison Tree Regression - Model
"""

from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

# Assuming X and y are defined as in your previous code snippet
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

tree_model = DecisionTreeRegressor(random_state=42)
tree_model.fit(X_train, y_train)

# Visualizing feature importances for different tree depths
max_depths = [2, 5, 10, 20, 50]  # Example list of tree depths to explore
feature_importances = []
for depth in max_depths:
    tree_model.set_params(max_depth=depth)
    tree_model.fit(X_train, y_train)
    feature_importances.append(tree_model.feature_importances_)

# Plotting feature importances against tree depths
plt.figure(figsize=(10, 6))
for i in range(len(X.columns)):
    plt.plot(max_depths, [importance[i] for importance in feature_importances], label=X.columns[i])

plt.xlabel('Max Depth of Tree')
plt.ylabel('Feature Importance')
plt.title('Feature Importances for Decision Tree Regressor')
plt.legend()
plt.show()

"""### Decision Tree Regression - Prediction"""

from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import cross_val_score

# Assuming X and y are defined as in your previous code snippet
tree_model = DecisionTreeRegressor(random_state=42)
tree_model.fit(X_train, y_train)

# Training error
y_pred_train = tree_model.predict(X_train)
train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))

print("Train Predictions:", y_pred_train[0:10])
print("Actual Train Values:", y_train[0:10].values)
print("Train RMSE:", train_rmse)

# Cross-validated RMSE
cv_rmse = np.sqrt(np.mean(-cross_val_score(tree_model, X_train, y_train, cv=20, scoring="neg_mean_squared_error")))
print("Cross-Validated RMSE:", cv_rmse)

# Test error
y_pred_test = tree_model.predict(X_test)
test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))
print("Test Error:", test_rmse)

"""### Decision Tree Regression - Model Tuning"""

# Hyperparameters to tune
param_grid = {
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

# Initialize Decision Tree Regressor
tree_model = DecisionTreeRegressor(random_state=42)

# Perform Randomized Search Cross Validation
tree_cv = RandomizedSearchCV(estimator=tree_model, param_distributions=param_grid,
                             scoring='neg_mean_squared_error', cv=10, n_iter=10, random_state=42)
tree_cv.fit(X_train, y_train)

# Get the best hyperparameters
best_params = tree_cv.best_params_
print("Best Hyperparameters:", best_params)

# Train a final model using the best hyperparameters
best_tree_model = DecisionTreeRegressor(**best_params, random_state=42)
best_tree_model.fit(X_train, y_train)

# Predict using the tuned model
y_pred = best_tree_model.predict(X_test)
test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))
print("Test RMSE with Tuned Model:", test_rmse)

"""### Gradient Boosting
* Gradient Boosting Regression reduces prediction errors by iteratively creating a series of decision trees, each correcting the errors of its predecessor, ultimately forming a robust ensemble model.
* It sequentially builds trees, focusing on areas where previous trees underperformed, combining their predictions to strengthen the overall model.
* Unlike linear regression, Gradient Boosting doesn't use explicit coefficients; instead, it optimizes by minimizing errors and iteratively improving predictions, employing ensemble learning to enhance accuracy without direct penalty-based regularization methods.*

### Gradient Boosting - Model
"""

from sklearn.ensemble import GradientBoostingRegressor
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

# Assuming X and y are defined as in your previous code snippet
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

gb_model = GradientBoostingRegressor(random_state=42)
gb_model.fit(X_train, y_train)

# Visualizing feature importances for different max depths
max_depths = [2, 5, 10, 20, 50]  # Example list of max depths to explore
feature_importances = []
for depth in max_depths:
    gb_model.set_params(max_depth=depth)
    gb_model.fit(X_train, y_train)
    feature_importances.append(gb_model.feature_importances_)

# Plotting feature importances against max depths
plt.figure(figsize=(10, 6))
for i in range(len(X.columns)):
    plt.plot(max_depths, [importance[i] for importance in feature_importances], label=X.columns[i])

plt.xlabel('Max Depth of Trees')
plt.ylabel('Feature Importance')
plt.title('Feature Importances for Gradient Boosting Regressor')
plt.legend()
plt.show()

"""### Gradient Boosting - Prediction"""

from sklearn.metrics import mean_squared_error
from sklearn.model_selection import cross_val_score

# Assuming X and y are defined as in your previous code snippet
gb_model = GradientBoostingRegressor(random_state=42)
gb_model.fit(X_train, y_train)

# Training error
y_pred_train = gb_model.predict(X_train)
train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))

print("Train Predictions:", y_pred_train[0:10])
print("Actual Train Values:", y_train[0:10].values)
print("Train RMSE:", train_rmse)

# Cross-validated RMSE
cv_rmse = np.sqrt(np.mean(-cross_val_score(gb_model, X_train, y_train, cv=20, scoring="neg_mean_squared_error")))
print("Cross-Validated RMSE:", cv_rmse)

# Test error
y_pred_test = gb_model.predict(X_test)
test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))
print("Test Error:", test_rmse)

"""### Gradient Boosting - Fine Tuning"""

from sklearn.model_selection import RandomizedSearchCV
# Hyperparameters to tune
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

# Initialize Gradient Boosting Regressor
gb_model = GradientBoostingRegressor(random_state=42)

# Perform Randomized Search Cross Validation
gb_cv = RandomizedSearchCV(estimator=gb_model, param_distributions=param_grid,
                           scoring='neg_mean_squared_error', cv=10, n_iter=10, random_state=42)
gb_cv.fit(X_train, y_train)

# Get the best hyperparameters
best_params = gb_cv.best_params_
print("Best Hyperparameters:", best_params)

# Train a final model using the best hyperparameters
best_gb_model = GradientBoostingRegressor(**best_params, random_state=42)
best_gb_model.fit(X_train, y_train)

# Predict using the tuned model
y_pred = best_gb_model.predict(X_test)
test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))
print("Test RMSE with Tuned Model:", test_rmse)

"""### Conclusion
| Model | Test RSME | FIne Tuned Test RSME|
|----------|----------|----------|
| Simple Linear Regression | 0.47 |              |
| Ridge Regression | 0.51 | 0.47 |
| Lasso Regression | 1.1 | 0.53 |
| Elastic Net Regression | 1.1 | 0.47 |
| Random Forest Regression| 0.41 | 0.41
| Decision Tree Regression| 0.61 | 0.54  
| Gradient Boosting Regression| 0.56 | 0.44 |

* If performance of regression models is measured by RSME :
  
  Random Forest Regression model and Gradient Boost model perform best  
"""

